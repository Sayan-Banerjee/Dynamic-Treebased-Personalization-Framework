{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BasicDataPrep_V1 import *\n",
    "from CLTreeModules import *\n",
    "from DataPrepForSeasonalityDetectionUsingBookingTrend_V1 import *\n",
    "from SeasonalityDetection_Discrete import *\n",
    "from SeasonalityDetection_Continuous import *\n",
    "from ReadWritePickleFile import *\n",
    "from PruneTreeByConqueringNodes import *\n",
    "from PruneTreeByMergingCentroids import *\n",
    "from ClusterTree_Utility import *\n",
    "from Attribute import *\n",
    "from ClusteringFromRules import *\n",
    "from ClusterTree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimpleAttributes(node, othersGroup):\n",
    "    # Assert node is an instance of CLNode\n",
    "    assert isinstance(node, CLNode)\n",
    "    \n",
    "    attributes = {}\n",
    "    i = 0 \n",
    "    while i<len(node.dataset.attr_names):\n",
    "        attr_name = node.dataset.attr_names[i]\n",
    "        uniqueValues = len(np.unique(node.dataset.getInstances(attr_name)))\n",
    "        \n",
    "        attributes[node.dataset.attr_names[i]]= Attribute(name=attr_name,\n",
    "                                                          noOfUniqueValues = uniqueValues,\n",
    "                                                          maxVal=node.dataset.max_values[i+1],\n",
    "                                                          minVal = node.dataset.min_values[i+1])\n",
    "\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    for key in attributes.keys():\n",
    "        if attributes[key].type == 'Calculated' and re.findall(\"_others$\", attributes[key].name)\\\n",
    "                and attributes[key].originalAttribute in othersGroup:\n",
    "            attributes[key].setOriginalAttributeVal(othersGroup[attributes[key].originalAttribute])\n",
    "        elif attributes[key].type == 'Calculated' and re.findall(\"_weekend$\", attributes[key].name):\n",
    "            attributes[key].setOriginalAttributeVal(['friday', 'saturday', 'fri', 'sat'])\n",
    "        elif attributes[key].type == 'Calculated' and re.findall(\"_midweek$\", attributes[key].name):\n",
    "            attributes[key].setOriginalAttributeVal(['tuesday','wednesday', 'thursday','tue', 'wed', 'thu'])\n",
    "        elif attributes[key].type == 'Calculated' and re.findall(\"_earlyweek$\", attributes[key].name):\n",
    "            attributes[key].setOriginalAttributeVal(['sunday', 'monday', 'sun', 'mon'])\n",
    "        \n",
    "            \n",
    "    return attributes\n",
    "\n",
    "def buildSimpleTree(CLNode, node, attributes):\n",
    "    #Check if ClusterTreeNode is None and CLNode is Root\n",
    "    curNode = ClusterTreeNode()\n",
    "    \n",
    "    if CLNode.includedInCluster:\n",
    "        curNode.setParent(node)\n",
    "        if CLNode.parent is None:\n",
    "            curNode.setInheriatedFraction(1.0)\n",
    "            if CLNode.clusterId is not None:\n",
    "                curNode.setClusterId(CLNode.clusterId.strip().lower())\n",
    "            else:\n",
    "                curNode.setClusterId('DEFAULT')\n",
    "        else:\n",
    "            curNode.setInheriatedFraction(CLNode.dataset.length()/CLNode.parent.dataset.length())\n",
    "            curNode.setClusterId(CLNode.clusterId.strip().lower())\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        attribute = CLNode.attribute\n",
    "        cutValue = CLNode.cutValue\n",
    "\n",
    "        if attributes[attribute].type == 'Categorical' or attributes[attribute].type == 'Calculated':\n",
    "            curNode.setAttribute(attribute=attributes[attribute].originalAttribute,\n",
    "                                 attributeType=attributes[attribute].type)\n",
    "            curNode.setValue(attributes[attribute].originalAttributeVal)\n",
    "\n",
    "        else:\n",
    "            curNode.setAttribute(attribute=attributes[attribute].originalAttribute, attributeType=attributes[attribute].type)\n",
    "            curNode.setValue(cutValue)\n",
    "            \n",
    "        if CLNode.depth>0:\n",
    "            curNode.setInheriatedFraction(CLNode.dataset.length()/CLNode.parent.dataset.length())\n",
    "        else:\n",
    "            curNode.setInheriatedFraction(0.)\n",
    "        curNode.setParent(node)\n",
    "        CLNodeChildren = CLNode.getChildNodes()\n",
    "        left = buildSimpleTree(CLNodeChildren[0], curNode, attributes)\n",
    "        curNode.setLeft(left)\n",
    "        right = buildSimpleTree(CLNodeChildren[1], curNode, attributes)\n",
    "        curNode.setRight(right)\n",
    "        \n",
    "    return curNode\n",
    "\n",
    "\n",
    "def __validateMinMaxCriteria(min_y, min_split_fraction, data_length,\n",
    "                             fractionOfTotalData, mergingCentroidsVsconqueringNodes, testMode):\n",
    "    if testMode:\n",
    "        return min_y, min_split_fraction\n",
    "    \n",
    "    assert fractionOfTotalData <=1.0 and fractionOfTotalData > 0.,\\\n",
    "        logger.error(\"The value of 'fractionOfTotalData' should be greater than 0 and less than or equal to 1.\")\n",
    "    if mergingCentroidsVsconqueringNodes:\n",
    "        initial_override_min_y = 1000.0\n",
    "    else:\n",
    "        initial_override_min_y = 750.0\n",
    "    \n",
    "    if data_length > 5000.0:\n",
    "        if fractionOfTotalData < 1.0:\n",
    "            initial_override_min_y = math.floor(initial_override_min_y * fractionOfTotalData)\n",
    "            \n",
    "    else:\n",
    "        if fractionOfTotalData < 1.0:\n",
    "            initial_override_min_y = math.floor(initial_override_min_y * fractionOfTotalData * (data_length/5000))\n",
    "    \n",
    "    min_y = max(initial_override_min_y, min_y)\n",
    "    \n",
    "    if not mergingCentroidsVsconqueringNodes:\n",
    "        min_split_fraction = min(min_split_fraction, (100/data_length))\n",
    "    else:\n",
    "        min_split_fraction = min(min_split_fraction, (min_y/data_length))\n",
    "    \n",
    "    logger.info(\"The min-split fraction has been set to {}\".format(min_split_fraction))\n",
    "    logger.info(\"The min_y (The minimum number of member required for a cluster) has been set to {}\".format(min_y))\n",
    "    \n",
    "    return min_y, min_split_fraction\n",
    "\n",
    "\n",
    "def __combine(monthsToTree, keys, attribute, defaultValues, curVer):\n",
    "    if len(keys) == 1:\n",
    "        key = keys[0]\n",
    "        return monthsToTree[key]\n",
    "        \n",
    "    curNode = ClusterTreeNode()\n",
    "    mid = math.ceil((len(keys)-1)/2)\n",
    "    keys_l = keys[:mid]\n",
    "    keys_r = keys[mid:]\n",
    "    subtree_l = __combine(monthsToTree,keys_l, attribute, defaultValues, curVer)\n",
    "    subtree_r = __combine(monthsToTree,keys_r, attribute, defaultValues, curVer)\n",
    "    cutValue = ()\n",
    "    for i in keys_r:\n",
    "        cutValue = cutValue + i\n",
    "    curNode.setAttribute(attribute=attribute, attributeType='Calculated')\n",
    "    curNode.setValue(list(cutValue))\n",
    "    curNode.setLeft(subtree_l.getRoot())\n",
    "    subtree_l.getRoot().setParent(curNode)\n",
    "    curNode.setRight(subtree_r.getRoot())\n",
    "    subtree_r.getRoot().setParent(curNode)\n",
    "    clusterTree = ClusterTree(curNode, defaultValues, curVer)\n",
    "    return clusterTree\n",
    "\n",
    "\n",
    "def __getClusterTreeFromData(data, categoricalAttributes, mergingCentroidsVsconqueringNodes, balancedPrune,\n",
    "                             min_y, min_split_fraction, conquerDataColumns, prefixString, defaultValues,\n",
    "                             useSilhouette, prevVer):\n",
    "    \n",
    "    if categoricalAttributes is not None:\n",
    "        othersGroup, data = getOthersGoup(data, categoricalAttributes, min_split_fraction)\n",
    "    else:\n",
    "        othersGroup = None\n",
    "\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    if not mergingCentroidsVsconqueringNodes:\n",
    "        if conquerDataColumns is not None:\n",
    "            conquerData = pd.DataFrame(data[conquerDataColumns].copy(deep=True))\n",
    "            data = data[list(set(data.columns)-set(conquerDataColumns))].copy(deep=True)\n",
    "        else:\n",
    "            conquerData = data.copy(deep=True)\n",
    "            \n",
    "        divideData = data.copy(deep=True)\n",
    "        \n",
    "                \n",
    "    d_var = dict(data.var())\n",
    "    d_cols = sorted(d_var, key=d_var.get, reverse=True)\n",
    "    data = data[d_cols]\n",
    "\n",
    "\n",
    "    r = DataFrameReader(data)\n",
    "    data = r.read()\n",
    "    min_split = np.ceil(data.length() * min_split_fraction)\n",
    "    cltree = CLTree(data, min_split)\n",
    "    cltree.buildTree()\n",
    "    min_y = max(min_y, min_split)\n",
    "    data_length = data.length()\n",
    "\n",
    "    if mergingCentroidsVsconqueringNodes:\n",
    "        result, baseVer = pruneByGridSearch_Centroid(cltree, min_y, data_length, prefixString, balancedPrune, useSilhouette)\n",
    "    else:\n",
    "        gradientTolerance = 0.01 # Tested with different values, looks like 0.01 is a good candidate\n",
    "        result, baseVer = pruneByGridSearch(cltree, min_y, prefixString, gradientTolerance, conquerData, divideData, useSilhouette)\n",
    "    \n",
    "    utc_now = datetime.datetime.now()\n",
    "    deltaVer = math.ceil(float((utc_now - datetime.datetime(1970, 1, 1)).total_seconds()))\n",
    "    deltaVer = float(\".\" + str(deltaVer))\n",
    "    \n",
    "    if math.floor(prevVer) == math.floor(baseVer):\n",
    "        curVer = baseVer + deltaVer\n",
    "    else:\n",
    "        curVer = baseVer\n",
    "    \n",
    "    attributes = getSimpleAttributes(node=cltree.root, othersGroup=othersGroup)\n",
    "    simpleTreeRoot = buildSimpleTree(CLNode=cltree.root, node = None, attributes=attributes)            \n",
    "    clusterTree = ClusterTree(simpleTreeRoot, defaultValues, curVer)\n",
    "    return clusterTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option can take values between (1,2,3)\n",
    "# Option 1 (option = 1)==> Provide Static Rule based Clustering. Please provide the Clustering Rules in a\n",
    "# Json|dictionary type Format. For reference consult DemoRuleBasedSegmentation.xlsx for clear and\n",
    "# better understanding of the rules, then writePickleFile.ipynb to see how to write that rule into .json| python dict. \n",
    "# Finally you can read the staticClustering.pickle to see the end product which will be used in cluster model building. \n",
    "# You will be able to see the visualization of the end product in RuleBasedClusterTree.gv.pdf. \n",
    "\n",
    "# Option 2 (option = 2)==> Dynamic Clustering WITHOUT taking into account \"Seasonality\" effect. Please provide the\n",
    "# historical data in a \".csv\" file with \"delimiter\"(another argument) specified. \";\" is preferred as delimeter.\n",
    "\n",
    "# Option 3 (option = 3)==> Dynamic Clustering with \"Seasonality\". Please provide the historical \n",
    "# data in a \".csv\" file with \"delimiter\"(another argument) specified. \";\" is preferred as delimeter.\n",
    "# Please consult the defination of \"Seasonality\" explained later in this section to better understand the task.\n",
    "# If you are choosing this option provide a viable value for \"keyStringForSeasonality\". \n",
    "\n",
    "# destinationPath ==> Is the path where the final model would be stored and later referenced at the transaction time. \n",
    "# We should have read and write access to this path and this path should be accessible from \"training\" and \"inference\"\n",
    "# location both. This is a path including the file name with extension(preferably .pickle).\n",
    "\n",
    "\n",
    "# staticClusterFilePath ==> If you have chosen \"option = 1\". This is path-variable to specify the location where\n",
    "# the static rules are stored in \".json|pickle etc.\" format. We should have read access from this location. \n",
    "# This is a path including the file name with extension(preferably .pickle).\n",
    "\n",
    "# storeID ==> Preferably a string which identifies uniquely the entity for which we are running this algorithm. \n",
    "# This value will be used in naming the cluster ids at the end. \n",
    "\n",
    "# histrocalDataFilePath ==> If you have chosen option = 2 or option = 3, this is the path where you specify where the\n",
    "# historical data file is stored. The historical data file is the file which holds the historical data, based on which\n",
    "# the segmenetations would be created and later will be used for inference. This file should be in \".csv\" format and \n",
    "# delimited by the sysmbol mentioned in \"delimiter\". \";\" is preferred as delimeter. We should have read access from this\n",
    "# location. This is a path including the file name with extension.\n",
    "\n",
    "# categoricalAttributes ==> This variable takes the name of columns from the historical data which are \"categorical\"\n",
    "# in nature. Categorical variables take on values that are names, labels, ids, codes etc.\n",
    "# Ex: Channel_id, language_id, Channel_name, language_name, language_id etc.\n",
    "# In case of historical data-based approach(option =2 or option =3), if you have some attribute which are categorical\n",
    "# in nature, mention them using “categoricalAttributes” variable. It can take “None” or one or multiple values.\n",
    "# Please assign its value based on your data at hand.EX: Suppose there is only one categorical variable(column)\n",
    "# you have in your data is “language_id”. Then, categoricalAttributes = “’language_id’”\n",
    "# Suppose there are two categorical variables(columns) you have in your data, lang_id and channel_id. Then,\n",
    "# categoricalAttributes = “[’lang_id’, ’channel_id’]”. Now suppose there are no categorical variable in your data,\n",
    "# then assign categoricalAttributes = “None”\n",
    "        \n",
    "# Seasonality Related Variable Definations:\n",
    "# (manualSeasonality, seasonalityDataPath, continuousVsDiscrete, keyStringForSeasonality)\n",
    "#    **Seasonality:** Grouping together few \"keyStringForSeasonality\" months. \n",
    "#     \"keyStringForSeasonality\" is something which is externally provided.\n",
    "#     \"keyStringForSeasonality\" should take value between **(\"arrival\", \"booking\", \"stay\" etc.)**\n",
    "#     suppose you want to do seasonality based on \"arrival_month\", mention \"keyStringForSeasonality\" = \"arrival\"\n",
    "#     and the data should have \"arrival_month\"|\"month_of_arrival\"|\"arrivalmonth\" etc. in the data colums by the\n",
    "#     time of training.\n",
    "#     If for some reason, you have mention something in \"keyStringForSeasonality\" but there is no column in data\n",
    "#     which associates with \"keyStringForSeasonality\" + \"month\" irrespective of their position,\n",
    "#     the algorithm will throw an error at the time of training. \n",
    "   \n",
    "#     Same for any other string you mention as \"keyStringForSeasonality\". How seasnality happens in a \n",
    "#     hotel/property/entity , it depends on the perpective of the people in-charge, how they look at their customer base.\n",
    "#     Also, we have to make sure that we apply seasonality based on something which we can pass at the backend at the time\n",
    "#     of transaction. Let's say, if \"stay\" is the keySting and we do not have ability to pass \"stay_month\" at the time\n",
    "#     of transaction going on, then we should not apply seasonality for that property. But if you think about it,\n",
    "#     \"arrival\" is close to \"stay\" so, if it is okay with everyone, and the we can replace the \"stay\" with \"arrival\"\n",
    "#     and we can pass \"arrival_month\" to the backend by the time of live transaction going on, then we should apply\n",
    "# \"arival\" as \"keyString\" by the time of training and inference. \n",
    "#     **In general as well, be sure that you are using the same variable name as the time of training vs inference\n",
    "#     otherwise the algotith willl not be able to recognise it and will assume default value for an attribute whenever\n",
    "#     necessary.**\n",
    "      \n",
    "#    **Continous Seasonality:** Grouping together months by similarity among them by some criteria which are only adjacent to each other.\n",
    "   \n",
    "#    **Discerete Seasonality:** Grouping together months by similarity among them by some criteria irrespective of adjacency.\n",
    "   \n",
    "# The way seasonality detection algorithm is designed, it is stateless. Only assumption it makes, \n",
    "# each row is representation is one month and the rows are sorted by month. Ex.: January at row 0 and\n",
    "# December at row 11 etc.\n",
    "# **\"option\" == 3 means you are asking for to detect seasnality from the data** and then create customer segmentation\n",
    "# for each season or group of months. \n",
    "# **\"continuousVsDiscrete\" is a boolean(True == Continuous, False == Discrete) flag**,\n",
    "# based on which \"continous\" or \"discrete\" seasonality detection gets triggered.\n",
    "# The default value for this flag is \"True\" (or Continuous). \n",
    "\n",
    "# Alternatively, suppose you want to **detect seasonality based on a different dataset than dataset used for core segmentation.** Ex. You have been provided a sales statistics and based on that we have to detect seasnality and once we have groupped together months based on the separate data, we will continue to our task of segmentation for each group of month based on the primary data. **\"seasonalityDataPath\" is the variable to provide path of secondary datasource to detect seasonality from it.**\n",
    "\n",
    "# In addition, one can choose to provide **\"manualSeasonality\". Ex:  manualSeasonality = [[1,2,3,4], [5,12,7], [6,8,9,10,11]]**\n",
    "\n",
    "# This customer segmentation solution is a 2 part solution. 1st part is essentially dividing\n",
    "# the whole data into small groups and 2nd part is bringing the small groups together to make managable size groups,\n",
    "# which is essentially conquering part of the algorithm. dividing parts happens on the data which avilable from the \n",
    "# session at the time of transaction but the conquering part can happen on any data it will depend on the\n",
    "# problem stament, business logic, data availability etc.\n",
    "\n",
    "# min_split_fraction ==> The value hold by this variable gets applied at the \"1st\" stage/operation(\"dividing\").\n",
    "# This fraction will detect how much granulaity you want to maintain in the samll groups. \n",
    "# Lets say, you have 100 records and you want full granularity, what it means is, if there is way to separate 2\n",
    "# data points logically by some attributes, do it till there is only 1 member left each node. In this case you\n",
    "# should mention your min_split_fraction = 0.01. On the other hand let's say, you are happy if a small group contains\n",
    "# less than (or equal to) 10 people. In that case, the \"dividing\" algorithm will stop splitting a dataset(subset)\n",
    "# further if it has total <=10 data points. 2 things you have to keep in mind when choosing a good value for\n",
    "# min_split_fraction. \n",
    "# 1. This algorithm pipeline has a dedicated conquer part, so you should maintain a good level of granularity, so that\n",
    "# the conquering algorithm can 2 similiar small groups easily. \n",
    "# 2. Too much granularity is not good always, it might have 2 adverse effect, i. The depth of the tree (search space)\n",
    "# would be larger than desiered and it will take more time to traverse the tree to get the segmentation label/id,\n",
    "# ii. Too much granularity can magnify noise and/or outliers in individual groups, as a result the conquering algorithm \n",
    "# might not perform as better as it could. \n",
    "\n",
    "# What would be good choice? Suppose you have 10000 data rows, group of 10 people is a good goto choice.\n",
    "# If you have 15000 data rows, group of 15 people is a good goto choice. So a potential good value for\n",
    "# min_split_fraction could be 0.001. But if you have only 5000 data rows, you might still want to maintain 10 people group \n",
    "# in that case the value of min_split_fraction would be 0.002. \n",
    " \n",
    "# whatFractionOfLast12MonthBySDBookings ==> This is fraction indicate what fraction of last 12 month's booking data is\n",
    "# getting used to represent the whole booking data. It takes a default value 1., which means we are passing\n",
    "# whole booking data. Now suppose let's say, we don't have PMS synch with one property and approx 50% of their booking\n",
    "# come from PMS, in that can we are only using 50% of the total booking data to represent their whole booking data,\n",
    "# in this case the value of this fraction should be 0.5. \n",
    "\n",
    "\n",
    "# mergingCentroidsVsconqueringNodes ==> This is a flag to indicate which 'conquering' algorithm will be spawned. If the\n",
    "# value of this flag is True, the \"conquering\" will happen by algorithm written in \"PruneTreeByMergingCentroids\". On the\n",
    "# other hand if the value of the flag is False, the \"conquering\" will happen by algorithm written in \n",
    "# \"PruneTreeByConqueringNodes\". Watch the 'inference' notebook to get a better understanding of difference between\n",
    "# two mechanisms. Both are valid and have performed well on all the testcases. Machine Learning is emprirical process,\n",
    "# it is not always easy to choose between 2 well performing algorithms specially in case of unsupervised learning\n",
    "# algorithms. \n",
    "# Here is my recommendation: \n",
    "#     1. If we are using the same dataset(same columns) for dividing and conquering or you are at the begining\n",
    "#     of conducting an experimental study without prior knowledge, use \"PruneTreeByMergingCentroids\". \n",
    "#     2. If we are using the different dataset(different columns) for dividing and conquering definately use \n",
    "#     \"PruneTreeByConqueringNodes\"\n",
    "\n",
    "# balancedPrune ==> This is a boolean flag to indicate if we want to have a balanced segmentation interms of number\n",
    "# of members at each segment. Generally our goal when doing segmentation is we want to keep similar things together and\n",
    "# different things far-apart. If the value of this flag is False, then we will stick to our original motivation and\n",
    "# we will pick the one scenario which fits to our original goal the best but the value of this flag is True, that means\n",
    "# we also care about the variations of the number data members in each group. We still care about the \"purity\" of each \n",
    "# group but we have an additional constraint here which tries to make the variations in the number of data memebers \n",
    "# among all the clusters as smalll as possible. \n",
    "# ** In both cases, we have a satifying constraint which is, we want atleast a certain number of members in each cluster. \n",
    "\n",
    "# conquerDataColumns ==> If we are using \"PruneTreeByConqueringNodes\" to conquering the small groups to bring them \n",
    "# together and assign a label/id to them by some criteria, we have choice to use the same columns as we have\n",
    "# already used to divide the whole dataset or we can use a different set of columns to do the same job\n",
    "# [THIS IS WHAT MAKES THIS ALGORITHM UNIQUE AND SPECIAL]. When we are using a different set of data to bring small\n",
    "# groups together please mention columns will be used in \"conquer\". The columns will be used in \"conquer\" will not\n",
    "# be used in \"divide\". If you are planning to use the same set of data columns to do the both task, please do not\n",
    "# mention anything here and pass the value as null/None. \n",
    "\n",
    "# min_y ==> This is satisfying constraint of the conquering part. The min_y takes real value to indicate how many\n",
    "# data points atleast we would need to qualify a group as a cluster. \n",
    "# useSilhouette ==> Is a Binary flag variable, default of it is False. If the value of this flag is True then the\n",
    "# \"Silhouette\" constant indicator will be claculated to determine the optimal number of clusters from a dataset \n",
    "# otherwise avg. intra-cluster distance/avg. inter-cluster distance will be used to determine the optimal number\n",
    "# of clusters from a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSimpleClusterTree(option=1, destinationPath=None, staticClusterFilePath=None,\n",
    "                           storeID=None, histrocalDataFilePath=None, categoricalAttributes=None,\n",
    "                           manualSeasonality=None, seasonalityDataPath=None, continuousVsDiscrete=True,\n",
    "                           keyStringForSeasonality='arrival', mergingCentroidsVsconqueringNodes = True, \n",
    "                           balancedPrune=False, conquerDataColumns=None,\n",
    "                           min_y=None, min_split_fraction=None, whatFractionOfLast12MonthBySDBookings=None,\n",
    "                           previousVersion=-1, missingDataTolerance=0.90, delimiter= ';',\n",
    "                           useSilhouette=False, testMode=False):\n",
    "    \n",
    "    if min_y is None:\n",
    "        min_y = 1000.0\n",
    "    if min_split_fraction is None and option == 2:\n",
    "        min_split_fraction = 0.001\n",
    "    elif min_split_fraction is None and option == 3:\n",
    "        min_split_fraction = 0.010\n",
    "        \n",
    "    if whatFractionOfLast12MonthBySDBookings is None:\n",
    "        whatFractionOfLast12MonthBySDBookings = 1.\n",
    "        \n",
    "    assert whatFractionOfLast12MonthBySDBookings>0. and whatFractionOfLast12MonthBySDBookings<=1.,\\\n",
    "    logger.error(\"The value of 'whatFractionOfLast12MonthBySDBookings' should be between 0(exclusive) and 1(inclusive)\")\n",
    "    assert destinationPath is not None, logger.error(\"Please provide a destination path to save the result!\")\n",
    "    assert (option == 1 and staticClusterFilePath is not None) or \\\n",
    "           (option in (2, 3) and histrocalDataFilePath is not None),\\\n",
    "        logger.error(\"Please provide the appropriate source file path and try again!\")\n",
    "\n",
    "    assert option in (1, 2, 3), logger.error(\"Please provide correct value as option. Acceptable values are 1,2,3!\")\n",
    "    \n",
    "    if previousVersion is None:\n",
    "        previousVersion = -1\n",
    "        \n",
    "    if option == 1:\n",
    "        \n",
    "        clusterTree = getClusterTreeFromRules(staticClusterFilePath, previousVersion)\n",
    "        \n",
    "    elif option in (2, 3):\n",
    "        if categoricalAttributes is not None:\n",
    "            if isinstance(categoricalAttributes, list):\n",
    "                categoricalAttributes = [i.lower().strip() for i in categoricalAttributes]\n",
    "            elif isinstance(categoricalAttributes, str):\n",
    "                categoricalAttributes = categoricalAttributes.lower().strip()\n",
    "        \n",
    "        if conquerDataColumns is not None:\n",
    "            assert isinstance(conquerDataColumns, list), \"'conquerDataColumns' needed to be provided in a list format!\"\n",
    "            conquerDataColumns = [i.lower().strip() for i in conquerDataColumns]\n",
    "\n",
    "        else:\n",
    "            if not mergingCentroidsVsconqueringNodes:\n",
    "                logger.warning(\"As 'conquerDataColumns' has not been provided,\\\n",
    "                                the algorithm will reuse the data used for creating the initial tree!\")\n",
    "\n",
    "        if keyStringForSeasonality is not None:\n",
    "            keyStringForSeasonality = keyStringForSeasonality.strip().lower()\n",
    "            \n",
    "        df, keyStringDateCol, keyStringWeekdayCol, keyStringMonthCol, defaultValues = \\\n",
    "            getData(histrocalDataFilePath, categoricalAttributes, keyStringForSeasonality,\n",
    "                            conquerDataColumns, missingDataTolerance, delimiter=delimiter)\n",
    "\n",
    "        if categoricalAttributes is not None and isinstance(categoricalAttributes, list) \\\n",
    "                and len(categoricalAttributes) > 0:\n",
    "\n",
    "            assert (set(categoricalAttributes).issubset(set(df.columns))),\\\n",
    "                logger.error(\"The name of categorical attributes don't match with data column names!\")\n",
    "\n",
    "        elif categoricalAttributes is not None and isinstance(categoricalAttributes, str):\n",
    "            assert categoricalAttributes in list(df.columns), \\\n",
    "                logger.error(\"The name of categorical attribute doesn't match with data column names!\")\n",
    "        \n",
    "        if option == 3:\n",
    "            if manualSeasonality is not None:\n",
    "                assert isinstance(manualSeasonality, dict) and\\\n",
    "                    all(isinstance(i, list) for i in list(manualSeasonality.values())) and \\\n",
    "                    len(manualSeasonality) <= 3 and len([j for i in list(manualSeasonality.values()) for j in i]) == 12\\\n",
    "                       and max([j for i in list(manualSeasonality.values()) for j in i]) == 12 and\\\n",
    "                        max([[j for i in list(manualSeasonality.values()) for j in i].count(x) for x in \\\n",
    "                            set([j for i in list(manualSeasonality.values()) for j in i])]) == 1,  \\\n",
    "                    logger.error(\"Please provide manual seasonality in correct format! The 'manualSeasonality'\\\n",
    "                                takes only 'dict'/key-value pair, where values are list of numerical value of months!\\\n",
    "                                One month can appear in only one season but one season can have any number of months!\")\n",
    "                \n",
    "                clusters = manualSeasonality\n",
    "                \n",
    "            else:\n",
    "                if seasonalityDataPath is not None:\n",
    "                    assert keyStringMonthCol is not None, logger.error(\"To apply seasonality to data\\\n",
    "                                            we would need to provide **Relevant Month related information!\")\n",
    "                    record = readSeparateSeasonalityDetectionData(sourcePath = seasonalityDataPath, delim=',')\n",
    "\n",
    "                else:\n",
    "                    assert keyStringWeekdayCol is not None and keyStringMonthCol is not None,\\\n",
    "                        logger.error(\"To detect seasonality we would need to provide\"\n",
    "                                     \" **Relevant Month and Weekday related information!\")\n",
    "                    seasonalityData  = df.copy(deep=True)\n",
    "                    seasonalityData, _map, bucketColName = bucketizeLeadDays(seasonalityData,\n",
    "                                                                             leadDaysColName='leaddays')\n",
    "                    record = dataPrepForClusteringByBookingTrend(seasonalityData, _map, keyStringDateCol,\n",
    "                                                                keyStringWeekdayCol, keyStringMonthCol,\n",
    "                                                                bucketColName='LeadDays_Bucket',\n",
    "                                                                groupByHowDissimilarToOthersTo=False)\n",
    "\n",
    "                if continuousVsDiscrete:  # True means we have been asked to provide continuous seasonality.\n",
    "                    if keyStringDateCol is not None:\n",
    "                        df_copy = df.copy(deep = True)\n",
    "                        instanceCountByMonth = df_copy[[keyStringDateCol, keyStringMonthCol]].\\\n",
    "                                                                drop_duplicates().reset_index(drop=True)\n",
    "                        del df_copy\n",
    "                        instanceCountByMonth = dict(instanceCountByMonth[keyStringMonthCol].value_counts())\n",
    "                    else:\n",
    "                        instanceCountByMonth = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, 7: 31, 8: 31, 9: 30, 10: 31,\n",
    "                                                11: 30, 12: 31}\n",
    "\n",
    "                    clusters = ClusterMonths_Continuous(ds_EachRowADataPoint=record,\n",
    "                                                        instanceCountByEachDataPoint=instanceCountByMonth,\n",
    "                                                        acceptableNumberOfClusters=[4, 5, 6])\n",
    "                else:  # False means if is okay to have group of months which are not adjacent to each other.\n",
    "                    clusters = ClusterMonths_Discrete(record, plot=False)\n",
    "\n",
    "                del record\n",
    "\n",
    "            if keyStringDateCol is not None:\n",
    "                df.drop(columns=keyStringDateCol, inplace=True)\n",
    "            logger.info(\"Cluster of months: {}\".format(clusters))\n",
    "            monthsToTree = {}\n",
    "            curVer = previousVersion\n",
    "            for c in clusters:\n",
    "                prefixString = ''.join([str(i) for i in clusters[c]])\n",
    "                prefixString = str(storeID) + '_' + prefixString + '_'\n",
    "                data = pd.DataFrame(df[df[keyStringMonthCol].isin(clusters[c])])\n",
    "                data.drop(columns=keyStringMonthCol, inplace = True)\n",
    "                \n",
    "                dataLength = len(data)\n",
    "                fractionOfTotalData = whatFractionOfLast12MonthBySDBookings\n",
    "\n",
    "                min_y, min_split_fraction = __validateMinMaxCriteria(min_y, min_split_fraction,\n",
    "                                                                     dataLength, fractionOfTotalData,\n",
    "                                                                     mergingCentroidsVsconqueringNodes, testMode)\n",
    "\n",
    "                tree = __getClusterTreeFromData(data, categoricalAttributes, mergingCentroidsVsconqueringNodes,\n",
    "                                                balancedPrune, min_y, min_split_fraction, conquerDataColumns,\n",
    "                                                prefixString, defaultValues, useSilhouette, previousVersion)\n",
    "\n",
    "                monthsToTree[tuple(clusters[c])] = tree\n",
    "                curVer = max(curVer, tree.versionOfClusterAlgo)\n",
    "                \n",
    "            attribute = keyStringMonthCol.strip().lower()\n",
    "            keys = list(monthsToTree.keys())\n",
    "            clusterTree = __combine(monthsToTree, keys, attribute, defaultValues, curVer)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            prefixString = str(storeID) + '_'\n",
    "\n",
    "            if keyStringDateCol is not None:\n",
    "                df.drop(columns=keyStringDateCol, inplace = True)\n",
    "            if keyStringMonthCol is not None:\n",
    "                df.drop(columns=keyStringMonthCol, inplace = True)\n",
    "                \n",
    "            dataLength = len(df)\n",
    "            fractionOfTotalData = whatFractionOfLast12MonthBySDBookings\n",
    "            min_y, min_split_fraction = __validateMinMaxCriteria(min_y, min_split_fraction, dataLength,\n",
    "                                                                 fractionOfTotalData,\n",
    "                                                                 mergingCentroidsVsconqueringNodes, testMode)\n",
    "\n",
    "             \n",
    "            clusterTree = __getClusterTreeFromData(df, categoricalAttributes, mergingCentroidsVsconqueringNodes,\n",
    "                                                   balancedPrune, min_y, min_split_fraction,conquerDataColumns,\n",
    "                                                   prefixString, defaultValues, useSilhouette, previousVersion)\n",
    "\n",
    "    attributes, clusters = getAttributesAndClusters(clusterTree)\n",
    "    flag = writePickleFile(path=destinationPath, data=clusterTree)\n",
    "    if not flag:\n",
    "        logger.error(\"The process has failed! Please Try Again!\")\n",
    "        return None\n",
    "    else:\n",
    "        logger.info(\"The process is successful!\")\n",
    "        return attributes, clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalAttributes = None\n",
    "histrocalDataFilePath = 'PPTData_WithProduct.csv'\n",
    "conquerDataColumns = ['Product-A', 'Product-B']\n",
    "\n",
    "destinationPath = './PPTData_WithProduct.pickle'\n",
    "storeID = 'PPTData_Model_w/o_products'\n",
    "continuousVsDiscrete = None\n",
    "keyStringForSeasonality = None\n",
    "balancedPrune = False\n",
    "mergingCentroidsVsconqueringNodes = False\n",
    "min_y = 3.\n",
    "min_split_fraction = 0.1\n",
    "whatFractionOfLast12MonthBySDBookings= 1.\n",
    "previousVersion=2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 13:08:44,627 - 4533695936 - INFO - All columns after feature engineering and before dropping any: ['product-a', 'languageenglish', 'product-b', 'languagespanish', 'leaddays', 'numberofpeople']\n",
      "2020-04-30 13:08:44,632 - 4533695936 - INFO - read 9\n",
      "2020-04-30 13:08:44,633 - 4533695936 - INFO - attribute names: [('id', <class 'float'>), ('leaddays', <class 'float'>), ('numberofpeople', <class 'float'>), ('languagespanish', <class 'float'>), ('languageenglish', <class 'float'>)]\n",
      "2020-04-30 13:08:44,634 - 4533695936 - INFO - This is the starting point!\n",
      "2020-04-30 13:08:44,637 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 25.0\n",
      "2020-04-30 13:08:44,638 - 4533695936 - INFO - At previous level(0), the cut happened on Attribute:leaddays, Value: 25.0\n",
      "2020-04-30 13:08:44,641 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 14.0\n",
      "2020-04-30 13:08:44,641 - 4533695936 - INFO - At previous level(1), the cut happened on Attribute:leaddays, Value: 14.0\n",
      "2020-04-30 13:08:44,644 - 4533695936 - INFO - At this level the best cut is found on Attribute: numberofpeople, at: 2.0\n",
      "2020-04-30 13:08:44,645 - 4533695936 - INFO - At previous level(2), the cut happened on Attribute:numberofpeople, Value: 2.0\n",
      "2020-04-30 13:08:44,648 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 7.0\n",
      "2020-04-30 13:08:44,649 - 4533695936 - INFO - At previous level(3), the cut happened on Attribute:leaddays, Value: 7.0\n",
      "2020-04-30 13:08:44,650 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 5.0\n",
      "2020-04-30 13:08:44,651 - 4533695936 - INFO - At previous level(4), the cut happened on Attribute:leaddays, Value: 5.0\n",
      "2020-04-30 13:08:44,652 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 3.0\n",
      "2020-04-30 13:08:44,654 - 4533695936 - INFO - At previous level(5), the cut happened on Attribute:leaddays, Value: 3.0\n",
      "2020-04-30 13:08:44,655 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 1.0\n",
      "2020-04-30 13:08:44,655 - 4533695936 - INFO - Inadequate data points to create further split on left child!\n",
      "2020-04-30 13:08:44,656 - 4533695936 - INFO - Level: 7, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[4. 1. 1. 0. 1.]\n",
      " Min :[4. 1. 1. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,657 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,658 - 4533695936 - INFO - Level: 7, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[6. 3. 2. 0. 1.]\n",
      " Min :[6. 3. 2. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,659 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,660 - 4533695936 - INFO - Level: 6, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[8. 5. 1. 0. 1.]\n",
      " Min :[8. 5. 1. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,661 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,662 - 4533695936 - INFO - Level: 5, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[5. 7. 2. 0. 1.]\n",
      " Min :[5. 7. 2. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,662 - 4533695936 - INFO - At previous level(3), the cut happened on Attribute:leaddays, Value: 7.0\n",
      "2020-04-30 13:08:44,663 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 10.0\n",
      "2020-04-30 13:08:44,664 - 4533695936 - INFO - Inadequate data points to create further split on left child!\n",
      "2020-04-30 13:08:44,665 - 4533695936 - INFO - Level: 5, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 0. 10.  1.  1.  0.]\n",
      " Min :[ 0. 10.  1.  1.  0.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,666 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,667 - 4533695936 - INFO - Level: 5, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 1. 12.  2.  1.  0.]\n",
      " Min :[ 1. 12.  2.  1.  0.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,667 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,668 - 4533695936 - INFO - Level: 3, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 7. 14.  3.  1.  0.]\n",
      " Min :[ 7. 14.  3.  1.  0.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,669 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,669 - 4533695936 - INFO - Level: 2, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 3. 25.  2.  0.  1.]\n",
      " Min :[ 3. 25.  2.  0.  1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,670 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:44,671 - 4533695936 - INFO - Level: 1, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 2. 35.  1.  0.  1.]\n",
      " Min :[ 2. 35.  1.  0.  1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:44,671 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,672 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,685 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,686 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,687 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,688 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,689 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,698 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,699 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,700 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,701 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,702 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,710 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,711 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,712 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,713 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,714 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,722 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,724 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,725 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 13:08:44,726 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,726 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,735 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,736 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,737 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,738 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,738 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,747 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,748 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,749 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,750 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,750 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,759 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,760 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,761 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,762 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,762 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,772 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,773 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,774 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,775 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,775 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,783 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,784 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,786 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,786 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,787 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,795 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,797 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,798 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,798 - 4533695936 - INFO - All Inv-Purities: {3.0: 0.0}\n",
      "2020-04-30 13:08:44,798 - 4533695936 - INFO - All intermediate stats, generated during grid search: {3.0: {'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}}\n",
      "2020-04-30 13:08:44,799 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:44,800 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:44,809 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 4, 2]),  #Clusters: 2.99, Inv-Purity: 0.0\n",
      "2020-04-30 13:08:44,810 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 5]),  #Clusters: 2, Inv-Purity: 0.36550402849608316\n",
      "2020-04-30 13:08:44,812 - 4533695936 - INFO - Search Mode: False.        Note: The underlying Tree structure got modified in the process of pruning to make the search space optimized!        'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.0, 'inter-cluster-distance': 0.981648190353195, 'purity': 0.0, 'data-points': {'PPTData_Model_w/o_products__cluster_0': 3, 'PPTData_Model_w/o_products__cluster_1': 4, 'PPTData_Model_w/o_products__cluster_DEFAULT': 2}}\n",
      "2020-04-30 13:08:44,814 - 4533695936 - INFO - The process is successful!\n"
     ]
    }
   ],
   "source": [
    "attributes, clusters = buildSimpleClusterTree(option=2, destinationPath=destinationPath, staticClusterFilePath=None,\n",
    "                           storeID=storeID, histrocalDataFilePath=histrocalDataFilePath, categoricalAttributes=categoricalAttributes,\n",
    "                           manualSeasonality=None, seasonalityDataPath=None, continuousVsDiscrete=continuousVsDiscrete,\n",
    "                           keyStringForSeasonality='arrival',mergingCentroidsVsconqueringNodes = mergingCentroidsVsconqueringNodes,\n",
    "                           balancedPrune=balancedPrune, conquerDataColumns=conquerDataColumns,\n",
    "                           min_y=min_y, min_split_fraction=min_split_fraction,\n",
    "                           whatFractionOfLast12MonthBySDBookings=whatFractionOfLast12MonthBySDBookings,\n",
    "                           previousVersion=previousVersion, missingDataTolerance=0.90,delimiter=';', testMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pptdata_model_w/o_products__cluster_0',\n",
       " 'pptdata_model_w/o_products__cluster_1',\n",
       " 'pptdata_model_w/o_products__cluster_default'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = readPicklefile('./PPTData_WithProduct.pickle')\n",
    "df = pd.read_csv('PPTData.csv', delimiter=\";\")\n",
    "preds = []\n",
    "for i in range(len(df)):\n",
    "    info = dict(df.loc[i])\n",
    "    pred, _ = model1.getClusterID(info) \n",
    "    preds.append(pred)\n",
    "df['Predicted_Cluster'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LeadDays</th>\n",
       "      <th>NumberOfPeople</th>\n",
       "      <th>LanguageEnglish</th>\n",
       "      <th>LanguageSpanish</th>\n",
       "      <th>Predicted_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model_w/o_products__cluster_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LeadDays  NumberOfPeople  LanguageEnglish  LanguageSpanish  \\\n",
       "0        10               1                0                1   \n",
       "1        12               2                0                1   \n",
       "2        35               1                1                0   \n",
       "3        25               2                1                0   \n",
       "4         1               1                1                0   \n",
       "5         7               2                1                0   \n",
       "6         3               2                1                0   \n",
       "7        14               3                0                1   \n",
       "8         5               1                1                0   \n",
       "\n",
       "                             Predicted_Cluster  \n",
       "0  pptdata_model_w/o_products__cluster_default  \n",
       "1  pptdata_model_w/o_products__cluster_default  \n",
       "2        pptdata_model_w/o_products__cluster_0  \n",
       "3        pptdata_model_w/o_products__cluster_1  \n",
       "4        pptdata_model_w/o_products__cluster_0  \n",
       "5        pptdata_model_w/o_products__cluster_1  \n",
       "6        pptdata_model_w/o_products__cluster_1  \n",
       "7        pptdata_model_w/o_products__cluster_1  \n",
       "8        pptdata_model_w/o_products__cluster_0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LeadDays</th>\n",
       "      <th>NumberOfPeople</th>\n",
       "      <th>LanguageEnglish</th>\n",
       "      <th>LanguageSpanish</th>\n",
       "      <th>Product-A</th>\n",
       "      <th>Product-B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LeadDays  NumberOfPeople  LanguageEnglish  LanguageSpanish  Product-A  \\\n",
       "0        10               1                0                1          0   \n",
       "1        12               2                0                1          0   \n",
       "2        35               1                1                0          1   \n",
       "3        25               2                1                0          1   \n",
       "4         1               1                1                0          1   \n",
       "5         7               2                1                0          1   \n",
       "6         3               2                1                0          1   \n",
       "7        14               3                0                1          1   \n",
       "8         5               1                1                0          1   \n",
       "\n",
       "   Product-B  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('PPTData_WithProduct.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalAttributes = None\n",
    "histrocalDataFilePath = 'PPTData.csv'\n",
    "conquerDataColumns = None\n",
    "\n",
    "destinationPath = './PPTData_Model.pickle'\n",
    "storeID = 'PPTData_Model'\n",
    "continuousVsDiscrete = None\n",
    "keyStringForSeasonality = None\n",
    "balancedPrune = False\n",
    "mergingCentroidsVsconqueringNodes = True\n",
    "min_y = 3.\n",
    "min_split_fraction = 0.1\n",
    "whatFractionOfLast12MonthBySDBookings= 1.\n",
    "previousVersion=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 13:08:48,321 - 4533695936 - INFO - All columns after feature engineering and before dropping any: ['languagespanish', 'leaddays', 'languageenglish', 'numberofpeople']\n",
      "2020-04-30 13:08:48,326 - 4533695936 - INFO - read 9\n",
      "2020-04-30 13:08:48,327 - 4533695936 - INFO - attribute names: [('id', <class 'float'>), ('leaddays', <class 'float'>), ('numberofpeople', <class 'float'>), ('languagespanish', <class 'float'>), ('languageenglish', <class 'float'>)]\n",
      "2020-04-30 13:08:48,328 - 4533695936 - INFO - This is the starting point!\n",
      "2020-04-30 13:08:48,331 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 25.0\n",
      "2020-04-30 13:08:48,332 - 4533695936 - INFO - At previous level(0), the cut happened on Attribute:leaddays, Value: 25.0\n",
      "2020-04-30 13:08:48,335 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 14.0\n",
      "2020-04-30 13:08:48,336 - 4533695936 - INFO - At previous level(1), the cut happened on Attribute:leaddays, Value: 14.0\n",
      "2020-04-30 13:08:48,339 - 4533695936 - INFO - At this level the best cut is found on Attribute: numberofpeople, at: 2.0\n",
      "2020-04-30 13:08:48,340 - 4533695936 - INFO - At previous level(2), the cut happened on Attribute:numberofpeople, Value: 2.0\n",
      "2020-04-30 13:08:48,343 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 7.0\n",
      "2020-04-30 13:08:48,344 - 4533695936 - INFO - At previous level(3), the cut happened on Attribute:leaddays, Value: 7.0\n",
      "2020-04-30 13:08:48,345 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 5.0\n",
      "2020-04-30 13:08:48,346 - 4533695936 - INFO - At previous level(4), the cut happened on Attribute:leaddays, Value: 5.0\n",
      "2020-04-30 13:08:48,348 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 3.0\n",
      "2020-04-30 13:08:48,348 - 4533695936 - INFO - At previous level(5), the cut happened on Attribute:leaddays, Value: 3.0\n",
      "2020-04-30 13:08:48,350 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 1.0\n",
      "2020-04-30 13:08:48,350 - 4533695936 - INFO - Inadequate data points to create further split on left child!\n",
      "2020-04-30 13:08:48,352 - 4533695936 - INFO - Level: 7, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[4. 1. 1. 0. 1.]\n",
      " Min :[4. 1. 1. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,352 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,353 - 4533695936 - INFO - Level: 7, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[6. 3. 2. 0. 1.]\n",
      " Min :[6. 3. 2. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,353 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,354 - 4533695936 - INFO - Level: 6, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[8. 5. 1. 0. 1.]\n",
      " Min :[8. 5. 1. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,355 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,355 - 4533695936 - INFO - Level: 5, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[5. 7. 2. 0. 1.]\n",
      " Min :[5. 7. 2. 0. 1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,357 - 4533695936 - INFO - At previous level(3), the cut happened on Attribute:leaddays, Value: 7.0\n",
      "2020-04-30 13:08:48,359 - 4533695936 - INFO - At this level the best cut is found on Attribute: leaddays, at: 10.0\n",
      "2020-04-30 13:08:48,359 - 4533695936 - INFO - Inadequate data points to create further split on left child!\n",
      "2020-04-30 13:08:48,360 - 4533695936 - INFO - Level: 5, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 0. 10.  1.  1.  0.]\n",
      " Min :[ 0. 10.  1.  1.  0.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,361 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,362 - 4533695936 - INFO - Level: 5, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 1. 12.  2.  1.  0.]\n",
      " Min :[ 1. 12.  2.  1.  0.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,362 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,363 - 4533695936 - INFO - Level: 3, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 7. 14.  3.  1.  0.]\n",
      " Min :[ 7. 14.  3.  1.  0.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,364 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,364 - 4533695936 - INFO - Level: 2, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 3. 25.  2.  0.  1.]\n",
      " Min :[ 3. 25.  2.  0.  1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,365 - 4533695936 - INFO - Inadequate data points to create further split on right child!\n",
      "2020-04-30 13:08:48,366 - 4533695936 - INFO - Level: 1, Datapoints: \n",
      "Data: 1\n",
      "['leaddays', 'numberofpeople', 'languagespanish', 'languageenglish']\n",
      " Max :[ 2. 35.  1.  0.  1.]\n",
      " Min :[ 2. 35.  1.  0.  1.]\n",
      "\n",
      "--------\n",
      "\n",
      "2020-04-30 13:08:48,367 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,367 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,370 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,372 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,373 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,373 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,374 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,376 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,377 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,379 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,380 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,380 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,382 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,383 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,384 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,385 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,385 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,387 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,389 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,390 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 13:08:48,391 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,392 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,394 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,395 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,396 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,397 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,397 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,399 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,400 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,401 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,402 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,403 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,405 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,407 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,408 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,409 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,409 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,412 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,413 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,415 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,415 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,416 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,418 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,419 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,420 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,421 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,422 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,424 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,425 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,427 - 4533695936 - INFO - Searching for 'min_y'. Current 'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,428 - 4533695936 - INFO - balancedPrune: False, All argminMetric: {3.0: 0.22297134511261876}\n",
      "2020-04-30 13:08:48,428 - 4533695936 - INFO - All intermediate stats, generated during grid search: {3.0: {'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}}\n",
      "2020-04-30 13:08:48,429 - 4533695936 - INFO - Printing MergeList: []\n",
      "2020-04-30 13:08:48,429 - 4533695936 - INFO - Printing Touching Nodes: {}\n",
      "2020-04-30 13:08:48,431 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([4, 3, 2]),  #Clusters: 2.99, argminMetric: 0.22297134511261876\n",
      "2020-04-30 13:08:48,432 - 4533695936 - INFO - Min_Y: 3.0, Scenario: dict_values([3, 6]),  #Clusters: 2, argminMetric: 0.47542782009509\n",
      "2020-04-30 13:08:48,434 - 4533695936 - INFO - Search Mode: False.            Note: The underlying Tree structure got modified in the process of pruning to make the search space optimized!            'min_y' = 3.0, 'result' = \n",
      "{'intra-cluster-distance': 0.23309748999337407, 'inter-cluster-distance': 1.0454145570841884, 'purity': 0.22297134511261876, 'varPurity': 0.9558029080856842, 'mean-members': 3.0, 'data-points': {'PPTData_Model__cluster_0': 4, 'PPTData_Model__cluster_1': 3, 'PPTData_Model__cluster_DEFAULT': 2}, 'argminMetric': 0.22297134511261876}\n",
      "2020-04-30 13:08:48,437 - 4533695936 - INFO - The process is successful!\n"
     ]
    }
   ],
   "source": [
    "attributes, clusters = buildSimpleClusterTree(option=2, destinationPath=destinationPath, staticClusterFilePath=None,\n",
    "                           storeID=storeID, histrocalDataFilePath=histrocalDataFilePath, categoricalAttributes=categoricalAttributes,\n",
    "                           manualSeasonality=None, seasonalityDataPath=None, continuousVsDiscrete=continuousVsDiscrete,\n",
    "                           keyStringForSeasonality='arrival', mergingCentroidsVsconqueringNodes = mergingCentroidsVsconqueringNodes,\n",
    "                           balancedPrune=balancedPrune, conquerDataColumns=conquerDataColumns,\n",
    "                           min_y=min_y, min_split_fraction=min_split_fraction,\n",
    "                           whatFractionOfLast12MonthBySDBookings=whatFractionOfLast12MonthBySDBookings,\n",
    "                           previousVersion=previousVersion, missingDataTolerance=0.90,delimiter=';', testMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pptdata_model__cluster_0',\n",
       " 'pptdata_model__cluster_1',\n",
       " 'pptdata_model__cluster_default'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = readPicklefile('./PPTData_Model.pickle')\n",
    "df = pd.read_csv('PPTData.csv', delimiter=\";\")\n",
    "preds = []\n",
    "for i in range(len(df)):\n",
    "    info = dict(df.loc[i])\n",
    "    pred, _ = model2.getClusterID(info) \n",
    "    preds.append(pred)\n",
    "df['Predicted_Cluster'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LeadDays</th>\n",
       "      <th>NumberOfPeople</th>\n",
       "      <th>LanguageEnglish</th>\n",
       "      <th>LanguageSpanish</th>\n",
       "      <th>Predicted_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pptdata_model__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pptdata_model__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model__cluster_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model__cluster_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model__cluster_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model__cluster_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model__cluster_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pptdata_model__cluster_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pptdata_model__cluster_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LeadDays  NumberOfPeople  LanguageEnglish  LanguageSpanish  \\\n",
       "0        10               1                0                1   \n",
       "1        12               2                0                1   \n",
       "2        35               1                1                0   \n",
       "3        25               2                1                0   \n",
       "4         1               1                1                0   \n",
       "5         7               2                1                0   \n",
       "6         3               2                1                0   \n",
       "7        14               3                0                1   \n",
       "8         5               1                1                0   \n",
       "\n",
       "                Predicted_Cluster  \n",
       "0        pptdata_model__cluster_1  \n",
       "1        pptdata_model__cluster_1  \n",
       "2  pptdata_model__cluster_default  \n",
       "3  pptdata_model__cluster_default  \n",
       "4        pptdata_model__cluster_0  \n",
       "5        pptdata_model__cluster_0  \n",
       "6        pptdata_model__cluster_0  \n",
       "7        pptdata_model__cluster_1  \n",
       "8        pptdata_model__cluster_0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
