{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruneTreeByConqueringNodes:\n",
    "    __init__:\n",
    "        Parameters:\n",
    "            prefixString: It is a predefined string which will be used when generating cluster ids.\n",
    "            cltree: The base cltree on which the pruning mechanism will be applied.\n",
    "                    This has to be an instance of CLTree.\n",
    "                    \n",
    "            conquerData: This is a seconadary data set by which you are planning to assign labels to the leaves of the\n",
    "                         CLTree. This has to be an instance of pandas.DataFrame.\n",
    "                    \n",
    "                         **Background**:Suppose we have to recommend a 5 products to a customer among 500 products. \n",
    "                                        At the time of transaction the only information available to us are the \n",
    "                                        some session-based/demographic information about the customer. \n",
    "                                        Scenario 1:At offline we have used only historical session-based/demographic\n",
    "                                                   data to do segmentation of managable number of clusters/segments.\n",
    "                                                   At the time of transaction we will get a\n",
    "                                                   cluster id based on customer's session-based/demograhic information\n",
    "                                                   and recommend a set of 5 products which are generically most liked\n",
    "                                                   by the calculated segment. In the segment there are people who have\n",
    "                                                   the similar demographic information.\n",
    "                                         \n",
    "                                        Scenario 2:At offline we have used historical session-based/demographic\n",
    "                                                   and buying behavior data together to do segmentation. First we\n",
    "                                                   divide the whole customer space into small groups (How small?, It \n",
    "                                                   depends on how granular and accurate the personalization requirement\n",
    "                                                   is. May be 5-10 people in a group) Then bring all the small groups\n",
    "                                                   together to create managabe number of clusters/segments with each of\n",
    "                                                   adequate size by the average historical buying behavior of each small\n",
    "                                                   group. At the end of the offline process we will assign a cluster id\n",
    "                                                   to each cluster. At the time of transaction we can still get the\n",
    "                                                   cluster id based on customer's session-based/demograhic information\n",
    "                                                   but and recommend a set of 5 products which are generically most \n",
    "                                                   liked by the calculated segment. But this time in the segment is\n",
    "                                                   there are people who have the similar buying behavior rather than\n",
    "                                                   similar demographic information.\n",
    "                                                \n",
    "                                        **Which scenario has better potential of providing personalized offer\n",
    "                                           to a customer consistently without leaving it to a \"chance\"?**\n",
    "                                                                    \n",
    "                \n",
    "        Operational Details: This is constructor of the \"PruneTreeByConqueringNodes\" class. Initializes few instance\n",
    "                             level variables.\n",
    "            \n",
    "    prune:\n",
    "        Parameters:\n",
    "            min_y: The \"min_y\" dictates the minimum number of data points required for a group to be \n",
    "                   considered as a cluster. This is an instance level variable.\n",
    "            gradientTolerance: Positive real number to indicate tolerance level when comparing 2 quality metric. \n",
    "                                This is a hyperparameter and also an instance level variable. \n",
    "            searchMode: Boolean Flag, to indicate if the current pruning process, which is happending as part of some\n",
    "                        grid search mechanism to calculate the best possible value for an hyper-parameter or not. \n",
    "                        If the value of this flag is False that means, we have already decided what would the values\n",
    "                        of all the relevant hyper parameters and therefore have freedom to modify the structure \n",
    "                        of the underlying CLTree to optimize the search space.\n",
    "                        If the value of the flag is True, we do not change the structure of the underlying CLTree, so\n",
    "                        that we can reset all the modfications after calculating the quality metric at the end of the\n",
    "                        process and revert back all changes made to the underlying CLTree and get back the original one,\n",
    "                        which would be used for other values of the hyper parameter we are trying to optimize for.\n",
    "                \n",
    "        Operational Details: This is the driver, only external facing and wrapper function of the class. The pruning\n",
    "                             process, whatever it may be, is controlled from here. \n",
    "                Algorithm:\n",
    "                    1. Set the value of instance level variable \"gradientTolerance\".\n",
    "                    2. Validate and set the value of instance level variable \"min_y\".\n",
    "                    3. Initialize instance level variable \"maxSoFar\"(will be used to create unique cluster id)\n",
    "                       and \"version\".\n",
    "                    4. Initialize the some active instance level variables, totalDataInstancesbyEachGroup, \n",
    "                        finalRepresentationVectors, finalRepresentationVectorsToCluster, originalRepresentationVectors\n",
    "                    5. Invoke, an internal function \"intializeTouchedNodes\" to set the \"touching nodes\" at each leaf\n",
    "                       node level for the underlying CLTree. \n",
    "                    6. Invoke, an internal function \"initializeRepresentationVectors\" to get the original set of\n",
    "                       representation vectors by each leaf node. [If there are some \"touching nodes\", the combination \n",
    "                        a leaf nodes and with all it's \"touching nodes\" appear once.].\n",
    "                    7. Get the final \"totalDataInstancesbyEachGroup\", \"finalRepresentationVectors\",\n",
    "                       \"finalRepresentationVectorsToCluster\" by invoking \"pruningTreeByMergingRepresentationVectors\" with\n",
    "                       instance variable \"originalRepresentationVectors\" and \"min_y\". \n",
    "                    8. Measure the final cluster statistics by invoking \"clusterStatistics\" function with \n",
    "                       instance level \"originalRepresentationVectors\", \"finalRepresentationVectors\",\n",
    "                       \"finalRepresentationVectorsToCluster\", \"totalDataInstancesbyEachGroup\" and store it in \"result\". \n",
    "                    9. If we are not currently searching of an optimized value for an hyper parameter and had decided\n",
    "                       on the values of all the parameters, then we are free to \"prune\" the underlying CLTree to \n",
    "                       optimize the search space. The optimization of the search space for the cost of little\n",
    "                       modificantion of the underlying CLTree doesn't change the result or any details other than \n",
    "                       may be depth/hight of some nodes where applicable. The process is performed by invoking \n",
    "                       \"pruningRedundantNodes\" with the \"root\" of the uinderlying CLTree. \n",
    "                    10. Return the final result to the calling function.\n",
    "                \n",
    "        \n",
    "    identifyingTouchedRegions:\n",
    "        Parameters:\n",
    "            root: An instance of CLNode which is root of a CLTree instance.\n",
    "                \n",
    "        Operational Details:\n",
    "            Defination:\n",
    "                **This operation is only valid for a CLTree.**\n",
    "                In a complex situation, it is possible that a broadly similar group of points got splited\n",
    "                into several regions either because the group is bounded by an irregular shape or because\n",
    "                in order to isolate one or more sparse region(s) from the original the underlying region,\n",
    "                it is cut into more than one piece.\n",
    "                \n",
    "                A region, Y1, is said to touch another region, Y2, on the i-th dimension on the lower bounding\n",
    "                surface (or the upper bounding surface), if they meet on the i-th dimension and intersect on all\n",
    "                other dimensions. That is,\n",
    "                1. max(Y1, i) = min(Y2, i) (or max(Y2, i) = min(Y1, i)) [for all i in cols./attrs. of data points]\n",
    "                2. And min(Y1, j) < max(Y2, j) and max(Y1, j) > min(Y2, j) [for all j ≠ i]\n",
    "                \n",
    "                **Algorithm**:\n",
    "                    1. Get the \"preordered\" list of leaves. [We are only concern about the leaves because at the end\n",
    "                                                          these are the only set of nodes which contains all the\n",
    "                                                          data points]\n",
    "                    2. Initialize \"mergeList\", a blank list which will hold the pair of leaves which are touching\n",
    "                                                            each-other by the above mentioned criterion.\n",
    "                    3. for node_preOrderedPos in range(len(PreOrderedList_of_leaves)):\n",
    "                        i. node = PreOrderedList_of_leaves[node_preOrderedPos]\n",
    "                        ii. get the min and max of all the attribute values of the node.\n",
    "                        iii. for all nxt_node in PreOrderedList_of_leaves[node_preOrderedPos:]:\n",
    "                            a. for each attr_i in attributes:\n",
    "                                **check for criteria 1. of the defination, if satisfies proceed to the step \"a)\"**\n",
    "                                    a) for each attr_j in attributes except attr_i:\n",
    "                                        **check for criteria 2. of the defination**\n",
    "                            b. if both criteria 1 and 2 are satisfied a pair of leaf node:\n",
    "                                a) Add the pair (node, nxt_node) to \"mergeList\".\n",
    "                            \n",
    "                            end for\n",
    "                        \n",
    "                        end for\n",
    "                        \n",
    "                    4. Declare an empty dictionary named \"touchingNodes\", which will contain standarized list of\n",
    "                            toching nodes for each node if a node is touching atleast one other node. \n",
    "                    5. if \"mergeList\" is not empty:\n",
    "                        a. invoke \"normalizingMergeList()\" with \"mergeList\",\n",
    "                                            it will return the content of \"touchingNodes\"\n",
    "                    6. Return \"touchingNodes\" to the calling function.\n",
    "                                \n",
    "                                    \n",
    "    \n",
    "    normalizingMergeList:\n",
    "        Parameters: \n",
    "            mergeList: list of pair of nodes which are touching each-other by defination of \"touching nodes\".\n",
    "                \n",
    "        Operational Details:\n",
    "            Create and return standarize list of touched nodes by each nodes respectively. This\n",
    "            function takes care of \"Commutative\" and \"Transitive\" property to create standarize list of\n",
    "            \"touching nodes\" for each node. \n",
    "            Ex.: mergeList: [(A,B), (C,D)] ==> touchingNodes: {A: [B], B: [A], C: [D], D:[C]}\n",
    "                 mergeList: [(A,B), (B,C)] ==> touchingNodes: {A: [B, C], B: [A, C], C: [A, B]}\n",
    "                        \n",
    "            returns touchingNodes to the calling function.\n",
    "            \n",
    "    \n",
    "    \n",
    "    calcModifiedDataLengthForEachnode:\n",
    "        Parameters: \n",
    "            node: An instance of CLNode (which is part of a CLTree instance).\n",
    "                \n",
    "        Operational Details:\n",
    "            This function initializes the \"modifiedLength\" property/attribute of CLNode.\n",
    "            After initializing the \"touching nodes\" for each node, the idea is the node itself and all the\n",
    "            touching node will **virtually** be considered a sigle node even though they are physically apart.\n",
    "            So if we want to know how many data points are there in any node at any given point of time, we\n",
    "            should include the length of data of \"touching nodes\" as well as virtually they are part of the\n",
    "            same node. \n",
    "            \n",
    "            This is a recursive function and operation on the CLTree is \"post-order\"[processing the children\n",
    "            first, then the node iself at any node] in nature.\n",
    "            \n",
    "            Algorithm:\n",
    "                1. if the node is Leaf:\n",
    "                    a. modfiedDataLength = own data length + ∑(data length of all \"touching nodes\")\n",
    "                    b. node.modifiedDataLength = modifiedDataLength\n",
    "                    c. return to the calling function\n",
    "                2. else:\n",
    "                    a. calculate the modifided data length of the left child.\n",
    "                    b. calculate the modifided data length of the right child.\n",
    "                    c. modfiedDataLength = left child modified data length + right child modified data length\n",
    "                    d. node.modifiedDataLength = modifiedDataLength\n",
    "                    e. return to the calling function\n",
    "                \n",
    "            This function set the values at the node level and doesn't return any value to the calling function.\n",
    "            \n",
    "    intializeTouchedNodes:\n",
    "        Parameters:\n",
    "            root: An instance of CLNode which is root of a CLTree instance.\n",
    "                \n",
    "        Operational Details:\n",
    "            This function is driver for getting a standrized list of \"touching nodes\" by each leaf nodes and set \n",
    "            the values for touchedNodes, modifiedLength at the CLNode instance level. \n",
    "            [Refer to \"identifyingTouchedRegions\" to get a clear idea about \"touching nodes\"]\n",
    "            Algorithm:\n",
    "                1. get the standrized list of \"touching nodes\" by each leaf nodes by invoking\n",
    "                                                                            \"identifyingTouchedRegions\".\n",
    "                2. Assign the list of \"touching nodes\" by each leaf nodes at CLNode instance level one by one. \n",
    "                3. calculate and initialize \"modifiedLength\" property/attribute of each CLNode by\n",
    "                                                             invoking \"calcModifiedDataLengthForEachnode\".\n",
    "            \n",
    "            This function set the values at the CLNode instance level and\n",
    "                                                doesn't return any value to the calling function.\n",
    "    \n",
    "    \n",
    "    _accountForTouchedNodesForRepresentationVectors:\n",
    "        Parameters:\n",
    "            preOrderedListofLeaves: A list of leaves which was generated by traversing the initial CLTree in preorder.\n",
    "            initialRepresentationVectors: A python dictionary containing the initial representation vector for each leaf.\n",
    "            totalCols: An integer indicating how many columns each representation vector/data has.\n",
    "                \n",
    "        Operational Details:\n",
    "            This is an internal helper function which is invoked from _calcInitialRepresentationVectors to calculate\n",
    "            the resultant representation vector by combining the representation vector of the \"touching nodes\" of each\n",
    "            leaf and return the modified collection of representation vectors to the calling function. \n",
    "            \n",
    "            Algorithm:\n",
    "                1. Declare an empty python dictionary to store and return the new set of representation vectors.\n",
    "                2. for each leaf in preOrderedListofLeaves:\n",
    "                    i. get the \"touching nodes\" of the current leaf. \n",
    "                    ii. if the current leaf node has any \"touching nodes\":\n",
    "                        a. add the current leaf node at the beginning of the list of \"touching nodes\".\n",
    "                        b. sort the current list of \"touching nodes\".\n",
    "                        c. if we are seeing the sorted current list of \"touching nodes\" first time:\n",
    "                            a. calculate the weighted average of all \"representationVectors\" of all the nodes\n",
    "                                                            in current list of \"touching nodes\".\n",
    "                            b. store the sorted current list of \"touching nodes\" as key and the result from previous\n",
    "                                        step as the value for future use to the python dictionary declared at step 1. \n",
    "                        d. if we have already seen the combination before, that mean this group is already accounted\n",
    "                                        for and we can now move to the next leaf in the preOrderedListofLeaves. \n",
    "                    iii. if the current leaf node doesn't have any \"touching nodes\", copy the current leaf node and\n",
    "                                        its representation vector to the python dictionary declared at step 1.\n",
    "                    end for\n",
    "                3. Return the new set of representation vectors to the calling function.\n",
    "                \n",
    "                    \n",
    "            \n",
    "    _calcInitialRepresentationVectors:\n",
    "        Parameters:\n",
    "            preOrderedListofLeaves: A list of leaves which was generated by traversing the initial CLTree in preorder.\n",
    "            idColPos: Postion of the id column in node dataset[which also is dividing dataset]. \n",
    "                \n",
    "        Operational Details:\n",
    "            This is a internal helper function, which is invoked from \"initializeRepresentationVectors\" function to do\n",
    "            the actual processings required to calculate the initial representation vectors of all leaves and then it\n",
    "            also invokes another internal helper function \"_accountForTouchedNodesForRepresentationVectors\" to account\n",
    "            for \"touching nodes\" of each leaf and put them in a same group and get the combined representation vector.\n",
    "            At the end return the set of representation  vectors to the \"initializeRepresentationVectors\".\n",
    "            \n",
    "            Algorithm:\n",
    "                1. for each leaf in preOrderedListofLeaves:\n",
    "                    i. Get the total actual data points resides at the current leaf.\n",
    "                    ii. Get the ids of actual data points resides at the current leaf.\n",
    "                    iii. Use the ids from step ii. to match and retrieve get the actual 'conquer' data points. \n",
    "                    iv. Calculate the average of all the 'conquer' data points at current leaf by\n",
    "                        using the information acquired at step i. and iii.\n",
    "                    v. end for\n",
    "                2. Invoke \"_accountForTouchedNodesForRepresentationVectors\" to account for \"touching nodes\" of each\n",
    "                    leaf and put them in a same group. \n",
    "                3. Return resultant \"representationVectors\" to the calling function. \n",
    "            \n",
    "                \n",
    "    \n",
    "    initializeRepresentationVectors:\n",
    "        Parameters:\n",
    "            root: An instance of CLNode which is root of a CLTree instance.\n",
    "                \n",
    "        Operational Details:\n",
    "            Each leaf in the previously built CLTree contains a small subset of data points from the original \n",
    "            set of the data points the procedure initially had started with. \n",
    "            **Note**: Other pruning mechanisms also have procedure with the same name.\n",
    "                      Each implemenetation is essentially different from others.  \n",
    "            **PruneTreeByConqueringNodes** specific details:\n",
    "                The main idea behind \"PruneTreeByConqueringNodes\" is, to use a separate dataset to group the small\n",
    "                groups(leaves) together to form clusters with each cluster will have a minimum number of data points.\n",
    "                It is also possible to reuse the same data which was used to create the initial CLTree. It is handled\n",
    "                through \"__getClusterTreeFromData\" function. This portion of the algorithm is essentially stateless. \n",
    "                It just works on the dataset, which has been passed to it as \"coquer\" dataset. The only two restrictions\n",
    "                are, \"coquer\" dataset has to be of DataFrame format and all the attributes/columns of the dataset have to\n",
    "                be of numerical type. The data points at each leaf has an id associated with it, the \"coquer\" dataset\n",
    "                also has id for each row. \"coquer\" dataset is an instance level attribute value. This portion of the\n",
    "                algorithm get the correct \n",
    "                subset of the \"coquer\" dataset from the entire set by matching ids from the data at each leaf to the\n",
    "                ids of the \"coquer\" dataset. Once all leaves got the their subset of \"coquer\" dataset, we calculate an\n",
    "                element-wise average of the subset of \"coquer\" dataset at each leaf to get the initial representation\n",
    "                vector of that leaf. At this point of time, each leaf has has its own representation vector which is \n",
    "                not shared. However, at this point we need to account for \"touching nodes\" for each leaf nodes. \n",
    "                \"touching nodes\" are the nodes which essentialy part of the same group by the \"dividing\" criteria but\n",
    "                got seprated to isolate some sparse regions from the dense regions. At this stage, we would need to\n",
    "                combine the representation vectors of a node with its \"touching nodes\" and get a shared representation\n",
    "                vector among itself and all its \"touching nodes\" and all the \"touching nodes\" of a leaf node along with\n",
    "                the leaf form an entity(a little larger group). The nodes which do not has any \"touching nodes\" forms\n",
    "                a group by itself. In the process it is been also ensured that all the groups only counted as once. \n",
    "                \n",
    "                Algorithm:\n",
    "                    1. validate the root.\n",
    "                    2. Get a preordered list of leaves of the initial CLTree [We are only concerned about leaves].\n",
    "                    3. get the position of id column in the \"dividing\" dataset from root.\n",
    "                    4. get the resultant representation  vector by invoking _calcInitialRepresentationVectors function\n",
    "                                    with preOrderedListofLeaves calculated at step 2, idColPos calculated at step 3.\n",
    "                    5. return the set of representation  vectors to the calling function.\n",
    "                    \n",
    "                \n",
    "            \n",
    "     **Defination**: A unit vector is a vector of length 1, sometimes also called a direction vector.To find a\n",
    "                     unit vector with the same direction as a given vector, we divide by the magnitude of the vector. \n",
    "                                                                  \n",
    "    _getUnitVectorOfRepresentationVectors:\n",
    "        Parameters:\n",
    "            representationVectors: A python dictionary, values of which are vectors. \n",
    "                \n",
    "        Operational Details: This is an internal utility function with restricted access. Given a collection of vectors\n",
    "                             this function converts all the underlying vectors into \"unit vector\" individually and \n",
    "                             return a dictionary with the same set of keys and respective unit-vectors of previously\n",
    "                             provided vectors. \n",
    "        \n",
    "    _recalculateRepresentationVectors:\n",
    "        Parameters:\n",
    "            key1: tuple of node id(s)\n",
    "            representationVector1: Current representation vector of the collection of nodes provided as key1.\n",
    "            key2: tuple of node id(s)\n",
    "            representationVector2: Current representation vector of the collection of nodes provided as key2.\n",
    "                \n",
    "        Operational Details: This is an internal utility function with restricted access. Given 2 collection of \n",
    "                             node ids and their respective representation vectors this function calculates weighted\n",
    "                             average of 2 represetation vectors based on number of actual data instances each\n",
    "                             collection encompasses and create a combined key from \"key1\" and \"key2\" and return the\n",
    "                             newly calculated weighted average of two initial vectors as the associated value of the\n",
    "                             new key to the calling function. \n",
    "    \n",
    "    \n",
    "    _calcDataInstancesbyEachGroup:\n",
    "        Parameters:\n",
    "            listOfNodeIds: A list of tuples of node ids.\n",
    "                \n",
    "        Operational Details: This is an internal utility function with restricted access. Given a list of collection\n",
    "                             of leaf node ids, this function calculates and returns how many actual data instances \n",
    "                             are there by each collection of node ids. \n",
    "        \n",
    "    \n",
    "    pruningTreeByMergingRepresentationVectors:\n",
    "        Parameters:\n",
    "            originalRepresentationVectors: A python dictionary containing the initial representation vector for\n",
    "                                           each initial group of leaf nodes [post accounted for \"touching nodes\"]\n",
    "            min_y: The minimum number of members required by each group of leaf nodes to be considered as an\n",
    "                individual cluster.\n",
    "                \n",
    "        Operational Details:\n",
    "            Base Algorithm:\n",
    "            Agglomerative Hierarchical Clustering: It is a type of clustering algorithm which starts by treating\n",
    "                each object as a singleton cluster. Next, pairs of clusters are successively merged until all\n",
    "                clusters have been merged into one big cluster containing all objects. The result is a\n",
    "                tree-based representation of the objects, named dendrogram.\n",
    "\n",
    "            Quality Metric:\n",
    "            Purity or Inv-Purity: intra-clusters-distance / inter-clusters-distance\n",
    "            intra-cluster-distance and inter-cluster-distance are two very common quality metric is used to\n",
    "            measure the quality of clusters or performance of the clustering algorithm. We always want to \n",
    "            minimize intra-cluster-distance and maximize inter-clusters-distance for a given set of clusters.\n",
    "            Here we have combined 2 term together and as we always want to minimize the numerator and maximize\n",
    "            the denominator, our goal would be to minimize the value of our “Quality Metric”.\n",
    "\n",
    "            Gradient Tolerance: \n",
    "            Broadly, this is a small positive value which enables to perform the very well known “elbow method”\n",
    "            automatically. The clustering algorithms have an inherent problem, the greater number of clusters result\n",
    "            in smaller intra-clusters-distance and greater inter-clusters-distance most of the time.\n",
    "            To resolve this issue visually we use elbow method to give preference smaller number of clusters to \n",
    "            the greater number of clusters. Gradient Tolerance is a small positive value which quantify the what \n",
    "            we look in visual elbow method.\n",
    "\n",
    "            Defense/Protection against outliers:\n",
    "            In clustering there is a common occurrence of a problem that there may be few data points scattered across\n",
    "            the hyper-plane which are not close to any well-formed groups. Now the question is how to handle it?\n",
    "            Here in our clustering scheme, we have an instance level parameter “min_y” which indirectly controls\n",
    "            the number of clusters by defining how many minimum data points we would need to identify a group as a\n",
    "            well-formed cluster. We don’t want to violate the integrity of well formed clusters to include some\n",
    "            outliers here and there, so one of the better way of handling this kind of scenario is form a separate\n",
    "            group of outliers by the name of “DEFAULT”, in this way we are protecting integrity of the well-formed\n",
    "            clusters and also creating mutually exclusive and exhaustive clusters. \n",
    "            We initiate the above-mentioned mechanism of “Protection against outliers” when the number of points\n",
    "            which are not part of a well-formed group is less than the instance level parameter “min_y”. \n",
    "            This way we are eliminating any possibility that they might form a well-formed cluster by merging\n",
    "            one to another. \n",
    "\n",
    "\n",
    "\n",
    "            This is the heart of the “PruneTreeByConqueringNodes”. At this point, our entire data space is\n",
    "            divided into small groups, we have their representation vectors and another parameter, “min_y”.\n",
    "            We will use the representation vectors as the source data to a hierarchical agglomerative clustering\n",
    "            to group together small groups to form bigger groups. We will keep merging the small groups to form\n",
    "            bigger groups until either all the remaining groups have “min_y” data points or total data points\n",
    "            left to be part of bigger groups is less than “min_y”. In case of the later, we temporarily bind all\n",
    "            the loose groups/data points which are not part of any qualified group and form a group.\n",
    "            Then we calculate the statistics of the current settings and store it for future reference.\n",
    "            Then we continue with the hierarchical agglomerative clustering until there is only 2 groups\n",
    "            remaining but from now on after each iteration, we take a snapshot of the settings and the statistics\n",
    "            for future reference. \n",
    "            At the end we take all the scenarios, calculate the quality metric and use gradient tolerance to\n",
    "            find out the best setting and return the best way to cluster to the calling function. \n",
    "\n",
    "            Algorithm:\n",
    "                1. Make a \"deep copy\" of initial representation vectors. \n",
    "                2. calculate number of data points at each small groups and make a \"deep copy\" of the result.\n",
    "                3. Get all the representation vectors in a way so that it can be directly used my the\n",
    "                   \"scipy.cluster.hierarchy\" for hirerchical clustering and also, create referece of the\n",
    "                    data points by using keys from the copy of the \"originalRepresentationVectors\" created at step 1.\n",
    "                    So that later when we will revisit the hirerarchical cluster tree from the bottom up manner\n",
    "                    we can referce the original CLTree nodes from there. \n",
    "                4. Min-Max normalization of the data which will be used for hierarchical clustering to remove any\n",
    "                   potential bias. \n",
    "                5. Hierarchical clustering on the normalized data. \n",
    "                6. declare an empty dictionary to store all the intermediate results as we are about to revisit the \n",
    "                   hierarchical cluster tree from bottom-up manner. \n",
    "                7. While there are more than 2 groups:\n",
    "                    i. get the 2 vertices got combined. \n",
    "                    ii. get the actual node ids(or tuple of node ids) from the refernce has been created at step 3. \n",
    "                    iii. Create a new new combination from the 2 tuple we got back at previous step. It will be used\n",
    "                        at id in to identify the combination of nodes.\n",
    "                    iv. create a new refernce with the newly created id and delete previous references. \n",
    "                    v. Check if all the groups at this moment has data points more or equal to \"min_y\". \n",
    "                        a. if so, take a snapshot of the current groups and move on to next iteration. \n",
    "                    vi. Otherwise, get 2 lists of groups which have atleast \"min_y\" datapoints and groups which do not\n",
    "                        respectively. \n",
    "                        a. Check if total members of the groups which do not have atleast \"min_y\" datapoints is\n",
    "                           less than \"min_y\". \n",
    "                            i> if so, combine all the non-qualified groups together to form a temporary default group.\n",
    "                            ii> take a snapshot of the current groups and move on to next iteration.\n",
    "                        b. Otherwise move-on to the next iteration. \n",
    "                        c. end if\n",
    "                    viii. end if\n",
    "                8. end while\n",
    "                9. Validation for no cluster found, it can happen due to bad value in parameters. \n",
    "                10. Now it is the time to revisit all the snapshots we have taken during our visit to dendogram\n",
    "                    to figure out the best possible setting by the chosen metric and \"gradientTolerance\". \n",
    "                11. Once we have finalized a setting, we assign an unique cluster id to each group in the\n",
    "                    finalized settings and also as a part of this process all the leaf nodes get assigned \n",
    "                    to a cluster id based on which group they belong to.\n",
    "                12. Rerturn the best setting, final representation vectors and a map from node ids to cluster ids to the\n",
    "                    calling function.\n",
    "                        \n",
    "        \n",
    "    _assigingClusterToInternalNodes:\n",
    "        Parameters:\n",
    "            scenario: Finalized cluster settings in python dictionary format. Where the keys are tuples made-up with\n",
    "                     CLTree node ids. \n",
    "                \n",
    "        Operational Details:\n",
    "            After finalizing the clusters and the leaf nodes each one encompasses, it is time to assign an unique \n",
    "            cluster id to each cluster. In addition to this, the purpose of this function is to set the cluster\n",
    "            flag of each leaf node one by one and assign the cluster-id to the node attribute based on which cluster \n",
    "            the underlying leaf node is part of. At the same time create a refernce from node ids to assigned\n",
    "            cluster ids and return the same to the calling function.\n",
    "    \n",
    "    **Defination**: In computer science, tree traversal (also known as tree search) is a form of graph traversal\n",
    "                    and refers to the process of visiting (checking and/or updating) each node in a tree data\n",
    "                    structure, exactly once. Such traversals are classified by the order in which the nodes are\n",
    "                    visited.\n",
    "                A Generic Pre-Order Traversal Algorithm:\n",
    "                    1. Check if the current node is empty or null.\n",
    "                    2. Display/Store the data part of the root (or current node).\n",
    "                    3. Traverse the left subtree by recursively calling the pre-order function.\n",
    "                    4. Traverse the right subtree by recursively calling the pre-order function.\n",
    "                                                                  \n",
    "                                                                  \n",
    "    preOrderTraversal:\n",
    "        Parameters:\n",
    "            node: Instance of CLNode class. \n",
    "            preOrderedList: Current list of visted leaf nodes of undelying CLTree.\n",
    "                \n",
    "        Operational Details: This is an internal utility recursive function which returns the pre-order list of\n",
    "                             visited **leaf nodes**. Unlike generic \"Pre-Order Traversal Algorithm\" this version\n",
    "                             doesn't return list of all the nodes. It visits all the nodes but returns only the leaf\n",
    "                             nodes in the order of traversal. \n",
    "                             \n",
    "                             Algorithm:\n",
    "                                      1. If the current node is a leaf node add the current node to the current list\n",
    "                                         of visted leaf nodes and return the current list.\n",
    "                                      2. If the current node is not a leaf node, get its children. \n",
    "                                         i. Invoke another copy of \"preOrderTraversal\" with the left child and current\n",
    "                                            list of visited leaf nodes and get back the modified current list of\n",
    "                                            visited leaf nodes. \n",
    "                                         ii. Invoke another copy of \"preOrderTraversal\" with the right child and current\n",
    "                                            list of visited leaf nodes and get back the modified current list of\n",
    "                                            visited leaf nodes.\n",
    "                                         iii. Return the modified current list of visited leaf nodes to the \n",
    "                                              calling function.\n",
    "                                \n",
    "            \n",
    "    preOrderTraversalofClusters:\n",
    "        Parameters:\n",
    "            node: Instance of CLNode class. \n",
    "            preOrderedList: Current list of visted leaf nodes of undelying CLTree which are part of some cluster.\n",
    "                \n",
    "       Operational Details: This is an internal utility recursive function which returns the pre-order list of\n",
    "                            visited **leaf nodes which are part of some cluster**. Unlike generic \n",
    "                            \"Pre-Order Traversal Algorithm\" this version doesn't return list of all the nodes. \n",
    "                            It visits all the nodes but returns only the leaf which are part of some cluster\n",
    "                            nodes in the order of traversal. \n",
    "                             \n",
    "                             Algorithm:\n",
    "                                      1. If the current node is part of some cluster add the current node to the\n",
    "                                         current list of visted \"includedInCluster\" nodes and return the current list.\n",
    "                                      2. If the current node is not \"includedInCluster\", then get its children. \n",
    "                                         i. If it is a leaf node, just return the unmodified current list of visited\n",
    "                                            leaf nodes which are part of some cluster.\n",
    "                                         ii. Invoke another copy of \"preOrderTraversalofClusters\" with the left child\n",
    "                                             and current list of visited \"includedInCluster\" nodes and get back the \n",
    "                                             modified current list of visited \"includedInCluster\" nodes. \n",
    "                                         iii. Invoke another copy of \"preOrderTraversal\" with the right child and \n",
    "                                              current list of visited \"includedInCluster\" nodes and get back the \n",
    "                                              modified current list of visited \"includedInCluster\" nodes.\n",
    "                                         iv. Return the modified current list of visited \"includedInCluster\" nodes to\n",
    "                                             the calling function.\n",
    "    \n",
    "    leafPrunning:\n",
    "        Parameters: \n",
    "            node: Instance of CLNode class. \n",
    "                \n",
    "        Operational Details: This is an internal utility recursive function which operate in a bottom-up fashion. \n",
    "                             At each level/node this function checks if 2 childern of a parent are part of the same\n",
    "                             cluster, if so we can safely assign the cluster at the parent level and by doing so, \n",
    "                             we are optimizing the search space by reducing it by one level at a time. \n",
    "    \n",
    "    _whichChild:\n",
    "        Parameters:\n",
    "            node: Instance of CLNode class. \n",
    "                \n",
    "        Operational Details: This is an internal utility function with restricted access, which, given a node,\n",
    "                             return a flag to indicate if the current node is left or right child of its parent. \n",
    "            \n",
    "    resetAllPruneNodes:\n",
    "        Parameters: \n",
    "            node: Instance of CLNode class.\n",
    "                \n",
    "        Operational Details: This is an utility recursive function which resets all the changes has been made\n",
    "                             at node level of the underlying CLTree as part of the current pruning process and revert\n",
    "                             back to its original structure.This funtion is called when doing grid search to find\n",
    "                             optimal values for the set of hyperparameters. \n",
    "            \n",
    "    clusterStatistics:\n",
    "        Parameters:\n",
    "            originalRepresentationVectors: Python dictionary consist of original representation vectors. Keys are the \n",
    "                                           original leaf nodes after \"touching nodes\" are accounted for and values\n",
    "                                           are respective representation vectors before\n",
    "                                           \"pruningTreeByMergingRepresentationVectors\" was invoked. \n",
    "            finalRepresentationVectors: Python dictionary consist of final representation vectors. Keys are the final\n",
    "                                        groups of leaf nodes in tuple format which together forms invidual clusters \n",
    "                                        and values are respective representation vectors after\n",
    "                                        \"pruningTreeByMergingRepresentationVectors\" operation is completed. \n",
    "            finalRepresentationVectorsToCluster: Python dictionary consist of mapping from collection of leaf nodes \n",
    "                                                 to assigned respective cluster ids.\n",
    "            totalDataInstancesbyEachGroup: Python dictionary consist of mapping from group of leaf nodes and total\n",
    "                                           number of data instances by each group.\n",
    "                                           \n",
    "                \n",
    "        Operational Details:\n",
    "            This function is reposible to calculate and return the key statistics including the quality metric of choice \n",
    "            which will be used to asses the quality of clustering. In this particular implementation the quality metric\n",
    "            is, purity or inv-purity, Formula: intraClusterDistance/interClusterDistance. Apart from the quality metric\n",
    "            this function also returns the \"intra-cluster-distance\", \"inter-cluster-distance\" and \"data-points\" \n",
    "            at each cluster under the provided setting. \n",
    "            \n",
    "            Algorithm:\n",
    "                1. Get the unit vector of each original and final representation vectors. \n",
    "                2. Create a map/dictionary for each final individual group of leaf nodes which was created \n",
    "                   by merging a subset of original set of leaf nodes. It would be useful at the time of calulating \n",
    "                   \"intra-cluster-distance\".\n",
    "                3. Create all possible pair of cluters. It would be useful at the time of\n",
    "                   calulating \"inter-cluster-distance\".\n",
    "                4. Invoke an internal function named, \"_calcClusterStatistics\" to get the \"inter-cluster-distance\"  and\n",
    "                   \"intra-cluster-distance\".\n",
    "                5. calculate the purity or inv-purity by \"intra-cluster-distance\"/\"inter-cluster-distance\".\n",
    "                6. Put all the statistics together. \n",
    "                7. return the result.\n",
    "    \n",
    "    _calcClusterStatistics:\n",
    "        Parameters:\n",
    "            allCombosOfFinalRepresentationVectors: All possible pair of cluters keys. It would be useful at the time of\n",
    "                                                   calulating \"inter-cluster-distance\"\n",
    "            finalRepresentationVectors: Python dictionary consist of final representation vectors. Keys are the final\n",
    "                                        groups of leaf nodes in tuple format which together forms invidual clusters \n",
    "                                        and values are respective representation vectors after\n",
    "                                        \"pruningTreeByMergingRepresentationVectors\" operation is completed.\n",
    "            originalRepresentationVectors: Python dictionary consist of original representation vectors. Keys are the \n",
    "                                            original leaf nodes after \"touching nodes\" are accounted for and values\n",
    "                                            are respective representation vectors before\n",
    "                                            \"pruningTreeByMergingRepresentationVectors\" was invoked.\n",
    "            finalToOriginalRepresentationVectorsMap: A python dictionary for each final individual group of leaf nodes\n",
    "                                                     which was created by merging a subset of original set of\n",
    "                                                     leaf nodes. It would be useful at the time of calulating \n",
    "                                                     \"intra-cluster-distance\".\n",
    "                \n",
    "        Operational Details: \n",
    "            This is an internal function which is called from \"clusterStatistics\", is responsible to \n",
    "             do the actual calculations required to calculate various cluster statistics including\n",
    "             \"intra-cluster-distance\" and \"inter-cluster-distance\" and return those to the calling function.\n",
    "                    \n",
    "        \n",
    "    _calcEuclidianDistance:\n",
    "        Parameters:\n",
    "            a: vector 1.\n",
    "            b: vector 2.\n",
    "                \n",
    "        Operational Details:\n",
    "            This is an utility function which calculates and returns the euclidian distance bewteen 2 vectors. \n",
    "    \n",
    "    getClusterID:      \n",
    "        Operational Details:\n",
    "            This function increment and get the current value of an instance level variable and then concatenate\n",
    "            the value with some predefined string to create and the return an unique id for a cluster.\n",
    "    \n",
    "    pruningRedundantNodes:\n",
    "        Parameters:\n",
    "            root: The root of the instance level CLTree.\n",
    "                \n",
    "        Operational Details:\n",
    "            This is an utility function. Purpose of this function is to make the search space of CLTree more efficient\n",
    "            after \"leafPrunning\" has happened. At core CLTree devides the dataset at any level like a binary search tree.\n",
    "            Suppose 2 leaf nodes are 1 generation apart, both are the same type of child of their respective parent and\n",
    "            at both respective parent level the cut has happend on the same attribute, then we can safely remove \n",
    "            one level from the existing CLTree. \n",
    "            **Note**: This method changes the structure of the core CLTree, so after this method is invoked the\n",
    "                      underlying CLTree can't be reused in grid-search or restored back to its original form.\n",
    "                      This method/function therefore should be only called during the final and permanent pruning\n",
    "                      process. \n",
    "            Each leaf node in CLTree holds an unique set of data, as we are removing one level, we would need to merge\n",
    "            the data of respective leaf node to the data set of the other leaf node which will represent the both leaves\n",
    "            together. \n",
    "            This is a bottom-up iterative procedure. \n",
    "    \n",
    "    _recalculateDepthOfEachNodes:\n",
    "        Parameters:\n",
    "            node: CLNode instance. Started with CLTree root. \n",
    "            depth: Current Depth of the node. Started woth 0.\n",
    "                \n",
    "        Operational Details:\n",
    "            This is a recursive procedure, the purpose of the procedure is recalculate the depth of all the nodes\n",
    "            of the CLTree after it has gone through some structural changes. It updates the depth at the node level.\n",
    "            \n",
    "    \n",
    "    _merging2Datasets:\n",
    "        Parameters:\n",
    "            dataset1: Instance of CLTreeModules.Data class associated with one CLNode instance.\n",
    "            dataset2: Instance of CLTreeModules.Data class associated with another CLNode instance.\n",
    "                \n",
    "        Operational Details:\n",
    "            This is an internal function called from \"pruningRedundantNodes\" to merge dataset of 2 nodes together when \n",
    "            reducing a level. Some basic validation is requiered before the merge. Ex.: Order of the columns\n",
    "            name of all the columns and data-types of all the columns need to be same among 2 participating dataset. \n",
    "            If all the validations are fruitful then we create a separate instance of CLTreeModules.Data class \n",
    "            by using the combined dataset of dataset1 and dataset2 and return the newly created instance back to\n",
    "            calling function.\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "pruneByGridSearch:\n",
    "    Parameters:\n",
    "        cltree: The original CLTree instance on which the whole puning mechanism will be performed.\n",
    "        min_y: The \"min_y\" dictates the minimum number of data points required for a group to be considered as a cluster.\n",
    "        prefixString: predefined string for cluster id.\n",
    "        gradientTolerance: Positive real number to indicate tolerance level when comparing 2 quality metric. \n",
    "        conquerData: Data used for bringing CLTree leaf nodes together to create clusters.  \n",
    "        divideData: Data used for deviding the whole data set. \n",
    "                    It will also act as a fall back data set to bringing CLTree leaf nodes together to create\n",
    "                    clusters in case the clustering using \"conquerData\" doesn't work out.\n",
    "    \n",
    "    Operational Details:\n",
    "        This is method to grid search on various parameter values required for creating cluster by pruning the initial\n",
    "        CLTree or merging the leaf nodes to form clusters. In this implementation, \"min_y\" is the only manually provided\n",
    "        value and also a hyper parameter. To get the most optimal value of \"min_y\" which will provide the best value for \n",
    "        the cost function, we do a grid search on 10 equally spaced values of \"min_y\" starting from\n",
    "        \"min_y\" - 10% of \"min_y\" to \"min_y\". At each value we create a instance of \"PruneTreeByConqueringNodes\" with\n",
    "        the original \"cltree\" and current value of \"min_y\". At the end of each pruning procedure, we store the current\n",
    "        qulaity metric with the current setting for future refernce. (Here in this implementation the cost/quality \n",
    "        metric is \"purity\"[actually inverse purity.], which is we are trying to minimize.) Then move to the new value of\n",
    "        \"min_y\". \n",
    "        At the end when we are done with testing all the potential values of \"min_y\". We take the value of \"min_y\" where\n",
    "        the quality metric is best to the final pruning with \"searchMode\" set to False. We set the base version of the \n",
    "        pruning algorithm and return the base version and the result to the calling function. After the final pruning\n",
    "        all the required changes has happened to the CLTree and CLNode level. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
